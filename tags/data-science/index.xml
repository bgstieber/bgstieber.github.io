<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science on Brad Stieber</title>
    <link>/tags/data-science/</link>
    <description>Recent content in Data Science on Brad Stieber</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>bgstieber@gmail.com (Brad Stieber)</managingEditor>
    <webMaster>bgstieber@gmail.com (Brad Stieber)</webMaster>
    <lastBuildDate>Mon, 28 May 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/data-science/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>An Introduction to the kmeans Algorithm</title>
      <link>/post/an-introduction-to-the-kmeans-algorithm/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      <author>bgstieber@gmail.com (Brad Stieber)</author>
      <guid>/post/an-introduction-to-the-kmeans-algorithm/</guid>
      <description>This post will provide an R code-heavy, math-light introduction to selecting the \(k\) in k means. It presents the main idea of kmeans, demonstrates how to fit a kmeans in R, provides some components of the kmeans fit, and displays some methods for selecting k. In addition, the post provides some helpful functions which may make fitting kmeans a bit easier.
kmeans clustering is an example of unsupervised learning, where we do not have an output weâ€™re explicitly trying to predict.</description>
    </item>
    
  </channel>
</rss>